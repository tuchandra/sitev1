<!DOCTYPE html>
<html>

<head>
    <title>Modular Apache Spark: Transform Your Code into Pieces - Tushar Chandra</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width">
    <link rel="stylesheet" type="text/css" href="/site/sakura.css">
</head>

<body id="modular_spark">

    <nav>
        <section>
            <span class="home">
                <a href="/site/">Home</a>
            </span>
            <span class="links">
                //
                <a href="/site/contact.html">Contact</a>
                //
                <a href="/site/about.html">About</a>
                //
                <a href="/site/projects.html">Projects</a>
            </span>
        </section>
    </nav>

    <main>
        <h1>Modular Apache Spark: Transform Your Code into Pieces</h1>
<p>Albert Franzi (SWE @ Alpha Health) - 4/25</p>
<hr />
<p>Slides available <a href="https://docs.google.com/presentation/d/19XWds36PwDeYQw3A9UwaRBZvDi5g2p79-9aljEWHknI/edit#slide=id.g41055d5fd6_0_62">here</a>. The audience was 60–70% data engineers, remainder data scientists and random others.</p>
<h2>Simplifying Spark code</h2>
<p>This is &quot;how we simplified our Spark code by modularizing it.&quot; Asked the questions to the data engineers:</p>
<ul>
<li>have you ever played with duplicated code in your Spark jobs?</li>
<li>have you ever had a code review turn into chaos?</li>
</ul>
<p>Talked about how the Spark job can be fragmented into:</p>
<ul>
<li>readers</li>
<li>transformers, including aliases, joins, formattesr, etc.</li>
<li>task context</li>
<li>writers</li>
</ul>
<p>For the <strong>Readers and Writers</strong>, he recommends:</p>
<ul>
<li>enforce schemas</li>
<li>use schemas to read only the fields you are going to use</li>
<li>provide Readers per dataset, and attach its sources to it</li>
<li>share schemas and sources between Readers and Writers</li>
<li>GDPR compliant <em>by design</em></li>
</ul>
<p>For <strong>Readers</strong>, he went through the code examples — just look at the slides.</p>
<p>For <strong>Transformers</strong>, he recommends providing a list of available trasnformations to your data scientists. That's what Uni is trying to do, so that's nice. Recommends the libraries <a href="https://github.com/MrPowers/spark-daria">spark-daria</a> for Spark and <a href="https://github.com/MrPowers/quinn">quinn</a> for Pyspark specifically.</p>
<p>For <strong>Task Contexts,</strong> you should … do … something. Have your data scientists write job runners that accept Readers and Writers as parameters (which also increases testability of the code, that's just dependency injection).</p>
<p>A question was asked about how you socialize available Transformers, and what data scientists do if they don't find what they need … the answer boils down to organizational communication, and having data scientists contribute back to your codebase.</p>
<p>Use currying within your Transformers to reduce reliance on schemas:</p>
<ul>
<li>
<p><a href="https://medium.com/@mrpowers/chaining-custom-dataframe-transformations-in-spark-a39e315f903c">Chaining Custom DataFrame Transformations in Spark</a></p>
</li>
<li>
<p><a href="https://medium.com/@mrpowers/schema-independent-dataframe-transformations-d6b36e12dca6">Schema Independent DataFrame Transformations with Spark</a></p>
</li>
</ul>
<h2>Increasing test coverage of Spark code</h2>
<p>Asked the question &quot;who here has put untested Spark code into production?&quot; and someone responded &quot;if we test in production then everything is tested!&quot;</p>
<p>Library <a href="https://github.com/holdenk/spark-testing-base">spark-testing-base</a> from Holden Karau at Google. It lets you use a shared SparkContext across tests. This boils down to &quot;please test your code,&quot; and this is made easier by testing each piece independently.</p>
<h2>Reducing test time execution</h2>
<p>&quot;How many of you are experiencing issues where your tests take too long? … Are the rest of you the ones who aren't testing?&quot;</p>
<p>This was fairly Scala specific, sadly, since he talked about the package Junit4Git. It basically lets you skip tests whose related code wasn't changed by integrating with Git. Great talk.</p>

    </main>

    <footer>
        <section>
            <p>&copy; 2019 Tushar Chandra
                (<a href="https://github.com/tuchandra">GitHub</a> // <a href="https://tusharc.dev/">Website</a>)
            </p>
        </section>
    </footer>

</body>

</html>